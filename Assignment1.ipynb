{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please fill out the information of your group!\n",
    "\n",
    "| <p style=\"text-align: center;\">First Name</p>  | <p style=\"text-align: center;\">Family Name</p> | Matr.-No. |\n",
    "| ---------------------------------------------- | ---------------------------------------------- | -------- |\n",
    "| <p style=\"text-align: left\">*Abel*</p>| <p style=\"text-align: left\">*Boros*</p> | *K11944603* |\n",
    "| <p style=\"text-align: left\">*Basit*</p>| <p style=\"text-align: left\">*Nadeem*</p> | *K12248140* |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align: center\">344.105/6/7 UE: Natural Language Processing (WS2022/23)</h2>\n",
    "<h1 style=\"color:rgb(0,120,170)\">Assignment 1</h1>\n",
    "<h2 style=\"color:rgb(0,120,170)\">Document Classification with Standard Machine Learning Methods</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgb(224, 243, 255)\">\n",
    "<b>Terms of Use</b><br>\n",
    "This  material is prepared for educational purposes at the Johannes Kepler University (JKU) Linz, and is exclusively provided to the registered students of the mentioned course at JKU. It is strictly forbidden to distribute the current file, the contents of the assignment, and its solution. The use or reproduction of this manuscript is only allowed for educational purposes in non-profit organizations, while in this case, the explicit prior acceptance of the author(s) is required.\n",
    "\n",
    "**Authors:** Navid Rekab-saz, Oleg Lesota<br>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Table of contents</h2>\n",
    "<ol>\n",
    "    <a href=\"#section-general-guidelines\"><li style=\"font-size:large;font-weight:bold\">General Guidelines</li></a>\n",
    "    <a href=\"#section-preprocessing\"><li style=\"font-size:large;font-weight:bold\">Task A: Pre-processing & Feature Extraction (15 points)</li></a>\n",
    "    <a href=\"#section-training\"><li style=\"font-size:large;font-weight:bold\">Task B: Training and Results Analysis (15 points)</li></a>\n",
    "    <a href=\"#section-optional\"><li style=\"font-size:large;font-weight:bold\">Task C: Linear Model Interpretability (2 extra point)</li></a>\n",
    "    \n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"section-general-guidelines\"></a><h2 style=\"color:rgb(0,120,170)\">General Guidelines</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgb(224, 243, 255)\">\n",
    "\n",
    "### Assignment objective\n",
    "\n",
    "The aim of this assignment is to implement a document (sentence) classification model using (standard) machine learning methods. The assignment in total has **30 points**; it also offers **2 extra points** which can cover any missing point.\n",
    "\n",
    "This Notebook encompasses all aspects of the assignment, namely the descriptions of tasks as well as your solutions and reports. Feel free to add any required cell for solutions. The cells can contain code, reports, charts, tables, or any other material, required for the assignment. Feel free to provide the solutions in an interactive and visual way! \n",
    "\n",
    "Please discuss any unclear point in the assignment in the provided forum in MOODLE. It is also encouraged to provide answers to your peer's questions. However when submitting a post, keep in mind to avoid providing solutions. Please let the tutor(s) know shall you find any error or unclarity in the assignment.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgb(224, 243, 255)\">\n",
    "\n",
    "### Libraries & Dataset\n",
    "\n",
    "The assignment should be implemented with recent versions of `Python` (>3.7). Any standard Python library can be used, so far that the library is free and can be simply installed using `pip` or `conda`. Examples of potentially useful libraries are `scikit-learn`, `numpy`, `scipy`, `gensim`, `nltk`, `spaCy`, and `AllenNLP`. Use the latest stable version of each library.\n",
    "\n",
    "To conduct the experiments, we use a subset of the `HumSet` dataset [1] (https://blog.thedeep.io/humset/). `HumSet` is created by the DEEP (https://www.thedeep.io) project – an open source platform which aims to facilitate processing of textual data for international humanitarian response organizations. The platform enables the classification of text excerpts, extracted from news and reports into a set of domain specific classes. The provided dataset contains the classes (labels) referring to the humanitarian sectors like agriculture, health, and protection. The dataset contains an overall number of 17,301 data points. \n",
    "\n",
    "Download the dataset from the Moodle page of the course.\n",
    "\n",
    "the provided zip file consists of the following files:\n",
    "- `thedeep.subset.train.txt`: Train set in csv format with three fields: sentence_id, text, and label.\n",
    "- `thedeep.subset.validation.txt`: Validation set in csv format with three fields: sentence_id, text, and label.\n",
    "- `thedeep.subset.test.txt`: Test set in csv format with three fields: sentence_id, text, and label.\n",
    "- `thedeep.subset.labels.txt`: Captions of the labels.\n",
    "- `thedeep.ToU.txt`: Terms of use of the dataset.\n",
    "\n",
    "[1] HumSet: Dataset of Multilingual Information Extraction and Classification for Humanitarian Crises Response\n",
    "*Selim Fekih, Nicolo' Tamagnone, Benjamin Minixhofer, Ranjan Shrestha, Ximena Contla, Ewan Oglethorpe and Navid Rekabsaz.* \n",
    "In Findings of the 2022 Conference on Empirical Methods in Natural Language Processing (Findings of EMNLP), December 2022.\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgb(224, 243, 255)\">\n",
    "\n",
    "### Submission\n",
    "\n",
    "Each group should submit the following two files:\n",
    "\n",
    "- One Jupyter Notebook file (`.ipynb`), containing all the code, results, visualizations, etc. **In the submitted Notebook, all the results and visualizations should already be present, and can be observed simply by loading the Notebook in a browser.** The Notebook must be self-contained, meaning that (if necessary) one can run all the cells from top to bottom without any error. Do not forget to put in your names and student numbers in the first cell of the Notebook. \n",
    "- The HTML file (`.html`) achieved from exporting the Jupyter Notebook to HTML (Download As HTML).\n",
    "\n",
    "You do not need to include the data files in the submission.\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"section-preprocessing\"></a><h2 style=\"color:rgb(0,120,170)\">Task A: Pre-processing & Feature Extraction (15 points)</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgb(224, 243, 255)\">\n",
    "    \n",
    "**Preprocessing (5 points).** Load the train, validation, and test sets. Study the text and according to your judgements, apply at least <ins>two text cleaning/preprocessing methods</ins>. Punctuations marks, numbers, dates, case-sensitivity are some examples of the elements which can be potentially considered for cleaning/preprocessing. Tokenize the result text with a tokenizer of your choice. Report your approaches to text cleaning and tokenization and the reasons of your choices. Provide some examples, showing the effects of the applied approaches on the text.\n",
    "\n",
    "**Creating dictionary (5 points).** Create a dictionary of vocabularies following the guidelines discussed in the lecture. Next, reduce the size of dictionary using a method of your choice, for instance by considering a cut-off threshold on the tokens with low frequencies. When removing tokens from the dictionary, consider a strategy for handling Out-Of-Vocabulary (OOV) tokens, namely the ones in the train/validation/test datasets that that are not anymore in the dictionary. Some possible strategies could be to remove OOVs completely from the texts, or to replace them with a special token like <OOV\\>. Explain your approaches and report the statistics of the dictionary before and after the reduction.\n",
    "\n",
    "**Creating sentence vectors (5 points).** Use the dictionary to prepare <ins>two variations of document representation vectors</ins>, separately for train, validation, and test sets. Both variations follow a Bag-of-Words approach with a different token weighting method. One applied weighting must be `tf-idf` and the other one can be any other method discussed in the lecture such as `tc`, `tf`, `BM25`. These term weighting methods should be implemented; using a library to readily calculate the term weightings is not allowed. Report the applied approaches. Calculate and report the sparsity rate of the vectors of train, validation, and test sets, namely what percentages of the vectors in each set are filled with zeros.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Preprocessing</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "\n",
    "def read_text(path_to_textfile):\n",
    "    return pd.read_csv(path_to_textfile, names=['sentence_id', 'text', 'label'])\n",
    "\n",
    "def text_to_lowercase(dataframe):\n",
    "    return dataframe['text'].apply(lambda text: text.lower())\n",
    "\n",
    "def remove_punctation(dataframe):\n",
    "    return dataframe['text'].apply(lambda text: re.sub(r'[^\\w\\s]', '', text))\n",
    "\n",
    "def tokenize(dataframe):\n",
    "    return dataframe['text'].apply(lambda text: nltk.word_tokenize(text))\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    lemmatized_text = [wordnet_lemmatizer.lemmatize(word) for word in text]\n",
    "    return lemmatized_text\n",
    "\n",
    "def remove_stopwords_in_text(text):\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    text_without_stopwords = [i for i in text if i not in stopwords]\n",
    "    return text_without_stopwords\n",
    "    \n",
    "def remove_stopwords_from_dataframe(dataframe):\n",
    "    return dataframe['text'].apply(lambda text: remove_stopwords_in_text(text))\n",
    "    \n",
    "def lemmatize_df(datafarme):\n",
    "    return datafarme['text'].apply(lambda text: lemmatize_text(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw data goes into the pipline in form of a pandas dataframe.\n",
    "# It must have a 'text' column which contains the actual text.\n",
    "# Returned: A datafarme with proprocessed 'text' column.\n",
    "preprocessing_pipeline = [text_to_lowercase, \n",
    "                          remove_punctation, \n",
    "                          tokenize, \n",
    "                          remove_stopwords_from_dataframe, \n",
    "                          lemmatize_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = read_text('./data/thedeep.subset.train.txt')\n",
    "validation_set = read_text('./data/thedeep.subset.validation.txt')\n",
    "test_set = read_text('./data/thedeep.subset.test.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We applied different preprocessing steps to clean our data, you can find the functions with a descriptive names in the field with the utility functions comment.\n",
    "Our pipeline looks like this:\n",
    "\n",
    "<b>text -> convert to lowercase letters -> remove punctation from the sentences -> tokenize the whole text -> get rid of the stopwords -> lemmatize the whole dataset.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT WITHOUT PREPROCESSING:\n",
      "In addition to the immediate life-saving interventions, UNICEF is taking action to protect 200 children who have arrived at the camps in Angola without their families.\n",
      "------------------------------------------------------------------------------------\n",
      "LOWERCASE:\n",
      "in addition to the immediate life-saving interventions, unicef is taking action to protect 200 children who have arrived at the camps in angola without their families.\n",
      "------------------------------------------------------------------------------------\n",
      "REMOVE PUNCTATION:\n",
      "in addition to the immediate lifesaving interventions unicef is taking action to protect 200 children who have arrived at the camps in angola without their families\n",
      "------------------------------------------------------------------------------------\n",
      "TOKENIZATION:\n",
      "['in', 'addition', 'to', 'the', 'immediate', 'lifesaving', 'interventions', 'unicef', 'is', 'taking', 'action', 'to', 'protect', '200', 'children', 'who', 'have', 'arrived', 'at', 'the', 'camps', 'in', 'angola', 'without', 'their', 'families']\n",
      "------------------------------------------------------------------------------------\n",
      "REMOVE STOPWORDS:\n",
      "['addition', 'immediate', 'lifesaving', 'interventions', 'unicef', 'taking', 'action', 'protect', '200', 'children', 'arrived', 'camps', 'angola', 'without', 'families']\n",
      "------------------------------------------------------------------------------------\n",
      "LEMMATIZATION:\n",
      "['addition', 'immediate', 'lifesaving', 'intervention', 'unicef', 'taking', 'action', 'protect', '200', 'child', 'arrived', 'camp', 'angola', 'without', 'family']\n",
      "------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "example_text = train_set.iloc[[0]].copy()\n",
    "print('TEXT WITHOUT PREPROCESSING:')\n",
    "print(example_text['text'][0])\n",
    "print('------------------------------------------------------------------------------------')\n",
    "print('LOWERCASE:')\n",
    "example_text['text'] = text_to_lowercase(example_text)[0]\n",
    "print(example_text['text'][0])\n",
    "print('------------------------------------------------------------------------------------')\n",
    "print('REMOVE PUNCTATION:')\n",
    "example_text['text'] = remove_punctation(example_text)[0]\n",
    "print(example_text['text'][0])\n",
    "print('------------------------------------------------------------------------------------')\n",
    "print('TOKENIZATION:')\n",
    "example_text['text'] = tokenize(example_text)\n",
    "print(example_text['text'][0])\n",
    "print('------------------------------------------------------------------------------------')\n",
    "print('REMOVE STOPWORDS:')\n",
    "example_text['text'] = remove_stopwords_from_dataframe(example_text)\n",
    "print(example_text['text'][0])\n",
    "print('------------------------------------------------------------------------------------')\n",
    "print('LEMMATIZATION:')\n",
    "example_text['text'] = lemmatize_df(example_text)\n",
    "print(example_text['text'][0])\n",
    "print('------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for function in preprocessing_pipeline:\n",
    "    train_set['text'] = function(train_set)\n",
    "    validation_set['text'] = function(validation_set)\n",
    "    test_set['text'] = function(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = train_set['label'].value_counts().reset_index()\n",
    "label_counts = label_counts.sort_values(by='label', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not interpret input 'count'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/zz/g5kmpjm90hx6rdzn5t_d4n4r0000gn/T/ipykernel_56467/1156993602.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Adjust the figure size as needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbarplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'count'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Label'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Count'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Label Counts in Train Set'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/minimal_ds/lib/python3.10/site-packages/seaborn/_decorators.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m             )\n\u001b[1;32m     45\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/minimal_ds/lib/python3.10/site-packages/seaborn/categorical.py\u001b[0m in \u001b[0;36mbarplot\u001b[0;34m(x, y, hue, data, order, hue_order, estimator, ci, n_boot, units, seed, orient, color, palette, saturation, errcolor, errwidth, capsize, dodge, ax, **kwargs)\u001b[0m\n\u001b[1;32m   3180\u001b[0m ):\n\u001b[1;32m   3181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3182\u001b[0;31m     plotter = _BarPlotter(x, y, hue, data, order, hue_order,\n\u001b[0m\u001b[1;32m   3183\u001b[0m                           \u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mci\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_boot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3184\u001b[0m                           \u001b[0morient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpalette\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaturation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/minimal_ds/lib/python3.10/site-packages/seaborn/categorical.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, hue, data, order, hue_order, estimator, ci, n_boot, units, seed, orient, color, palette, saturation, errcolor, errwidth, capsize, dodge)\u001b[0m\n\u001b[1;32m   1582\u001b[0m                  errwidth, capsize, dodge):\n\u001b[1;32m   1583\u001b[0m         \u001b[0;34m\"\"\"Initialize the plotter.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1584\u001b[0;31m         self.establish_variables(x, y, hue, data, orient,\n\u001b[0m\u001b[1;32m   1585\u001b[0m                                  order, hue_order, units)\n\u001b[1;32m   1586\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestablish_colors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpalette\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaturation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/minimal_ds/lib/python3.10/site-packages/seaborn/categorical.py\u001b[0m in \u001b[0;36mestablish_variables\u001b[0;34m(self, x, y, hue, data, orient, order, hue_order, units)\u001b[0m\n\u001b[1;32m    151\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                     \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Could not interpret input '{}'\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;31m# Figure out the plotting orientation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Could not interpret input 'count'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))  # Adjust the figure size as needed\n",
    "sns.barplot(x='label', y='count', data=label_counts)\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Label Counts in Train Set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Creating a dictionary</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "\n",
    "def get_tokens_as_list(dataframe):  \n",
    "    corpus = dataframe['text'].tolist()\n",
    "    corpus = [word for sublist in corpus for word in sublist]\n",
    "    return corpus\n",
    "\n",
    "def get_wordfrequencies_from_list(corpus):\n",
    "    wordfrequencies = {}\n",
    "    for word in corpus:\n",
    "        if word not in wordfrequencies.keys():\n",
    "            wordfrequencies[word] = 1\n",
    "        else:\n",
    "            wordfrequencies[word] += 1\n",
    "    return wordfrequencies\n",
    "\n",
    "def filter_words(list_of_tokens, dictionary):\n",
    "    # Delete the tokens which is not part of the dictionary\n",
    "    return [token for token in list_of_tokens if token in dictionary]\n",
    "    \n",
    "def oov_on_dataframe(dataframe, dictionary):\n",
    "    return dataframe['text'].apply(lambda text: filter_words(text, dictionary))\n",
    "\n",
    "def token_counter(dataframe, column_name):\n",
    "    dataframe[column_name] = dataframe['text'].apply(len)\n",
    "    return dataframe\n",
    "\n",
    "# The collection of functions, this is the only one which needed to be called.\n",
    "def BOW(dataframe):\n",
    "    corpus = get_tokens_as_list(dataframe)\n",
    "    wordfrequencies = get_wordfrequencies_from_list(corpus)\n",
    "\n",
    "    # Sort the dictionary by frequencies\n",
    "    wordfrequencies = dict(sorted(wordfrequencies.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "    # Remove words with low frequency (< 200)\n",
    "    wordfrequencies = {key: value for key, value in wordfrequencies.items() if value >= 200}\n",
    "    \n",
    "    dataframe = token_counter(dataframe, 'token count')\n",
    "\n",
    "    # Delete the words which are not part of the wordfrequencies dictionary\n",
    "    dataframe['text'] = oov_on_dataframe(dataframe, wordfrequencies)\n",
    "\n",
    "    dataframe = token_counter(dataframe, 'token count after oov')\n",
    "    \n",
    "    return dataframe, wordfrequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, bow_train_dict = BOW(train_set)\n",
    "test_set, bow_test_dict = BOW(test_set)\n",
    "validation_set, bow_val_dict = BOW(validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token count</th>\n",
       "      <th>token count after oov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12110.000000</td>\n",
       "      <td>12110.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>44.773410</td>\n",
       "      <td>24.101321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>39.938087</td>\n",
       "      <td>22.800909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>57.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1489.000000</td>\n",
       "      <td>787.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        token count  token count after oov\n",
       "count  12110.000000           12110.000000\n",
       "mean      44.773410              24.101321\n",
       "std       39.938087              22.800909\n",
       "min        4.000000               0.000000\n",
       "25%       21.000000              10.000000\n",
       "50%       35.000000              18.000000\n",
       "75%       57.000000              31.000000\n",
       "max     1489.000000             787.000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[['token count', 'token count after oov']].describe()\n",
    "# The average token in a list decreased from 44.77 to 24.10, it's an average decrease of 20.67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token count</th>\n",
       "      <th>token count after oov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2595.000000</td>\n",
       "      <td>2595.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>43.578805</td>\n",
       "      <td>9.328324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>34.168370</td>\n",
       "      <td>8.807683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>351.000000</td>\n",
       "      <td>110.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       token count  token count after oov\n",
       "count  2595.000000            2595.000000\n",
       "mean     43.578805               9.328324\n",
       "std      34.168370               8.807683\n",
       "min       5.000000               0.000000\n",
       "25%      21.000000               4.000000\n",
       "50%      35.000000               7.000000\n",
       "75%      55.000000              12.000000\n",
       "max     351.000000             110.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set[['token count', 'token count after oov']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token count</th>\n",
       "      <th>token count after oov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2596.000000</td>\n",
       "      <td>2596.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>44.456086</td>\n",
       "      <td>9.935670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>37.882162</td>\n",
       "      <td>9.742509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>777.000000</td>\n",
       "      <td>111.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       token count  token count after oov\n",
       "count  2596.000000            2596.000000\n",
       "mean     44.456086               9.935670\n",
       "std      37.882162               9.742509\n",
       "min       5.000000               0.000000\n",
       "25%      21.000000               4.000000\n",
       "50%      35.000000               7.000000\n",
       "75%      56.000000              13.000000\n",
       "max     777.000000             111.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_set[['token count', 'token count after oov']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Creating sentence vectors</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_word_matrix(dataframe, wordfrequencies):\n",
    "    list_of_words = list(wordfrequencies.keys())\n",
    "    column_names = ['sentence_id'] + list_of_words + ['labels']\n",
    "    df = pd.DataFrame(0, index=range(len(dataframe)), columns=column_names)\n",
    "    df.iloc[:, 0] = dataframe['sentence_id']\n",
    "    df.iloc[:, -1] = dataframe['label']\n",
    "    \n",
    "    for i, word in enumerate(list_of_words):\n",
    "        for j, document in enumerate(dataframe['text']):\n",
    "            count = document.count(word)\n",
    "            df.at[j, word] = count\n",
    "        \n",
    "    return df\n",
    "\n",
    "def term_frequency(x):\n",
    "    return np.log(1 + x)\n",
    "\n",
    "# This function suppose that we have the basic document word matrix with the term counts\n",
    "def count_term_frequency_on_df(dataframe):\n",
    "    df = dataframe.copy()\n",
    "    df.iloc[:, 1:-1] = df.iloc[:, 1:-1].applymap(term_frequency)\n",
    "    return df\n",
    "\n",
    "def inverse_document_freq(dataframe):\n",
    "    idf_dict = {column: (np.log(dataframe.shape[0] / ((dataframe[column] > 0).sum() + 1))) if (dataframe[column] > 0).sum() > 0 else 0 for column in dataframe.columns[1:-1]}\n",
    "    return idf_dict\n",
    "\n",
    "def tf_idf(count_term_matrix, idf):\n",
    "    count_term_matrix_temp = count_term_matrix.copy()\n",
    "    \n",
    "    for index, row in count_term_matrix_temp.iterrows():\n",
    "        for column_name, value in row.iloc[1:-1].items():\n",
    "            count_term_matrix_temp.at[index, column_name] = value * idf[column_name]\n",
    "            \n",
    "    return count_term_matrix_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the term count matrix here.\n",
    "document_word_matrix_train = document_word_matrix(train_set, bow_train_dict)\n",
    "document_word_matrix_test = document_word_matrix(test_set, bow_test_dict)\n",
    "document_word_matrix_val = document_word_matrix(validation_set, bow_val_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_dict_train = inverse_document_freq(document_word_matrix_train)\n",
    "count_term_train_matrix = count_term_frequency_on_df(document_word_matrix_train)\n",
    "tf_idf_train = tf_idf(count_term_train_matrix, idf_dict_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_dict_test = inverse_document_freq(document_word_matrix_test)\n",
    "count_term_test_matrix = count_term_frequency_on_df(document_word_matrix_test)\n",
    "tf_idf_test = tf_idf(count_term_test_matrix, idf_dict_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_dict_val = inverse_document_freq(document_word_matrix_val)\n",
    "count_term_val_matrix = count_term_frequency_on_df(document_word_matrix_val)\n",
    "tf_idf_val = tf_idf(count_term_val_matrix, idf_dict_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>case</th>\n",
       "      <th>food</th>\n",
       "      <th>people</th>\n",
       "      <th>area</th>\n",
       "      <th>reported</th>\n",
       "      <th>child</th>\n",
       "      <th>health</th>\n",
       "      <th>2017</th>\n",
       "      <th>water</th>\n",
       "      <th>...</th>\n",
       "      <th>season</th>\n",
       "      <th>hospital</th>\n",
       "      <th>may</th>\n",
       "      <th>average</th>\n",
       "      <th>south</th>\n",
       "      <th>rate</th>\n",
       "      <th>risk</th>\n",
       "      <th>february</th>\n",
       "      <th>local</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>633</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.361419</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14014</td>\n",
       "      <td>2.466922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.194986</td>\n",
       "      <td>1.306843</td>\n",
       "      <td>2.785793</td>\n",
       "      <td>1.296367</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.395857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12225</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10181</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2591</th>\n",
       "      <td>5109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.071297</td>\n",
       "      <td>1.392896</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2592</th>\n",
       "      <td>5696</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.090923</td>\n",
       "      <td>3.051786</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.107138</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.885404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2593</th>\n",
       "      <td>4622</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.087068</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2594</th>\n",
       "      <td>9053</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.087068</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595</th>\n",
       "      <td>6095</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.087068</td>\n",
       "      <td>1.194986</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2596 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentence_id      case  food    people      area  reported     child  \\\n",
       "0             633  0.000000   0.0  0.000000  0.000000  0.000000  0.000000   \n",
       "1            6001  0.000000   0.0  0.000000  0.000000  0.000000  0.000000   \n",
       "2           14014  2.466922   0.0  0.000000  0.000000  1.194986  1.306843   \n",
       "3           12225  0.000000   0.0  0.000000  0.000000  0.000000  0.000000   \n",
       "4           10181  0.000000   0.0  0.000000  0.000000  0.000000  0.000000   \n",
       "...           ...       ...   ...       ...       ...       ...       ...   \n",
       "2591         5109  0.000000   0.0  0.000000  0.000000  0.000000  2.071297   \n",
       "2592         5696  0.000000   0.0  1.090923  3.051786  0.000000  0.000000   \n",
       "2593         4622  0.000000   0.0  0.000000  1.087068  0.000000  0.000000   \n",
       "2594         9053  0.000000   0.0  0.000000  1.087068  0.000000  0.000000   \n",
       "2595         6095  0.000000   0.0  0.000000  1.087068  1.194986  0.000000   \n",
       "\n",
       "        health      2017     water  ...  season  hospital       may  average  \\\n",
       "0     0.000000  0.000000  0.000000  ...     0.0       0.0  0.000000      0.0   \n",
       "1     0.000000  0.000000  4.361419  ...     0.0       0.0  0.000000      0.0   \n",
       "2     2.785793  1.296367  0.000000  ...     0.0       0.0  0.000000      0.0   \n",
       "3     0.000000  0.000000  0.000000  ...     0.0       0.0  0.000000      0.0   \n",
       "4     0.000000  0.000000  0.000000  ...     0.0       0.0  0.000000      0.0   \n",
       "...        ...       ...       ...  ...     ...       ...       ...      ...   \n",
       "2591  1.392896  0.000000  0.000000  ...     0.0       0.0  0.000000      0.0   \n",
       "2592  0.000000  0.000000  3.107138  ...     0.0       0.0  1.885404      0.0   \n",
       "2593  0.000000  0.000000  0.000000  ...     0.0       0.0  0.000000      0.0   \n",
       "2594  0.000000  0.000000  0.000000  ...     0.0       0.0  0.000000      0.0   \n",
       "2595  0.000000  0.000000  0.000000  ...     0.0       0.0  0.000000      0.0   \n",
       "\n",
       "      south  rate  risk  february  local  labels  \n",
       "0       0.0   0.0   0.0  0.000000    0.0       9  \n",
       "1       0.0   0.0   0.0  0.000000    0.0      11  \n",
       "2       0.0   0.0   0.0  3.395857    0.0       4  \n",
       "3       0.0   0.0   0.0  0.000000    0.0       7  \n",
       "4       0.0   0.0   0.0  0.000000    0.0       9  \n",
       "...     ...   ...   ...       ...    ...     ...  \n",
       "2591    0.0   0.0   0.0  0.000000    0.0       4  \n",
       "2592    0.0   0.0   0.0  0.000000    0.0       7  \n",
       "2593    0.0   0.0   0.0  0.000000    0.0       3  \n",
       "2594    0.0   0.0   0.0  0.000000    0.0      10  \n",
       "2595    0.0   0.0   0.0  0.000000    0.0       9  \n",
       "\n",
       "[2596 rows x 77 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"section-training\"></a><h2 style=\"color:rgb(0,120,170)\">Task B: Training and Results Analysis (15 points)</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgb(224, 243, 255)\">\n",
    "\n",
    "To evaluate the models, use <ins>accuracy</ins> as the metric throughout the task. \n",
    "\n",
    "**Dummy baseline (2 points).** Create one dummy baseline classifier that predicts the validation/test labels only based on the distribution of the labels in the training set (without any use of the feature vectors). This is a weak baseline and acts as a sanity check for the actual classifiers.\n",
    "\n",
    "**Training and tuning classifiers (5 points).** Select at least <ins>two classification algorithms</ins> from standard machine learning classifiers. Using each classification algorithm, train a machine learning model on each of the variations of feature vectors. This should result in <ins>four experiment sets</ins> (2 variations of feature vectors × 2 classification algorithms). The ML model in each of the experiments possibly have several involving hyper-parameters. For each experiment, select <ins>one of the hyper-parameters and tune its value</ins>. The tuning process is done by first assigning at least <ins>three values</ins> to the hyper-parameter, then training separate models based on each value, and finally using the evaluation results on the validation set to select the best-performing model. Report the studied hyper-parameters, the evaluation results of each on validation set, and finally the selected value of the hyper-parameter. \n",
    "\n",
    "**Evaluation, reporting results, and discussion (3 point).** Evaluate the selected models of the four experiments on the test set. Report the results of <ins>the four experiments on both validation and test sets (side by side) in one table as well as in one plot</ins>. Compare different experiments and models. Are the test results lower(/higher) than the validation results? If it is the case, where can it be rooted from? Among all these models and variations, what are the most important factors improving the classification results?\n",
    "\n",
    "**Confusion matrix (2 point).** Select the best performing model among the experiments and use it to create a confusion matrix. The matrix shows the predicted versus true results per each label. Explain your observations on the matrix. Across which classes do you observe significant confusions?\n",
    "\n",
    "**Features visualization (3 point).** Continue with the best performing model and now take its feature vectors for the *dataitems in the test set*. Project these feature vectors to a 2-dimensional space using the TSNE method.  Using these 2-dimensional vectors, create two plots where the dataitems are shown as points (small circles) on the plots. The plots look exactly the same but only differ in the coloring of the data points. The first plot colors every dataitem with its *true label*, while the second one colors each according to its *predicted label by the model*. Keep in mind to assign the same colors to the classes of the plots, so that the plots are visually comparable. Put these two plots side by side, observe the differences, and compare the results. Report your observations.\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.15832049306625579\n",
      "Test accuracy: 0.16878612716763006\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Train a dummy classifier on the training data\n",
    "dummy_clf = DummyClassifier(strategy='stratified', random_state=0)\n",
    "dummy_clf.fit(train_set['text'], train_set['label'])\n",
    "\n",
    "# Predict the labels for the validation and test sets\n",
    "val_pred = dummy_clf.predict(validation_set['text'])\n",
    "test_pred = dummy_clf.predict(test_set['text'])\n",
    "\n",
    "# Calculate the accuracy of the dummy classifier on the validation and test sets\n",
    "val_accuracy = accuracy_score(validation_set['label'], val_pred)\n",
    "test_accuracy = accuracy_score(test_set[\"label\"], test_pred)\n",
    "\n",
    "print(f'Validation accuracy: {val_accuracy}')\n",
    "print(f'Test accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Tuning Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with TF-IDF best params: {'C': 1}\n",
      "SVM with TF-IDF best score: 0.7558216350123865\n",
      "RF with TF-IDF best params: {'n_estimators': 1000}\n",
      "RF with TF-IDF best score: 0.7615194054500414\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "svm_clf = SVC(random_state=0)\n",
    "rf_clf = RandomForestClassifier(random_state=0)\n",
    "\n",
    "# Define the hyper-parameters to tune\n",
    "param_grid_svm = {'C': [0.1, 1, 10]}\n",
    "param_grid_rf = {'n_estimators': [10, 100, 1000]}\n",
    "\n",
    "# Grid search objects \n",
    "GS_svm = GridSearchCV(svm_clf, param_grid_svm, cv=5, scoring='accuracy')\n",
    "GS_rf = GridSearchCV(rf_clf, param_grid_rf, cv=5, scoring='accuracy')\n",
    "\n",
    "GS_svm.fit(tf_idf_train.iloc[:, 1:-1], train_set['label'])\n",
    "GS_rf.fit(tf_idf_train.iloc[:, 1:-1], train_set['label'])\n",
    "\n",
    "# Get the best parameters and scores\n",
    "best_params_svm_tf_idf = GS_svm.best_params_\n",
    "best_score_svm_tf_idf = GS_svm.best_score_\n",
    "best_params_rf_tf_idf = GS_rf.best_params_\n",
    "best_score_rf_tf_idf = GS_rf.best_score_\n",
    "\n",
    "# Print the results\n",
    "print(f'SVM with TF-IDF best params: {best_params_svm_tf_idf}')\n",
    "print(f'SVM with TF-IDF best score: {best_score_svm_tf_idf}')\n",
    "print(f'RF with TF-IDF best params: {best_params_rf_tf_idf}')\n",
    "print(f'RF with TF-IDF best score: {best_score_rf_tf_idf}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [501, 12110]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/zz/g5kmpjm90hx6rdzn5t_d4n4r0000gn/T/ipykernel_56467/1453734635.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Fit the grid search objects to the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mgrid_search_svm_bow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbow_train_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mgrid_search_rf_bow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbow_train_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/minimal_ds/lib/python3.10/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0mrefit_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    800\u001b[0m         \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_fit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/minimal_ds/lib/python3.10/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/minimal_ds/lib/python3.10/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    333\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [501, 12110]"
     ]
    }
   ],
   "source": [
    "# Define the grid search objects for BoW\n",
    "grid_search_svm_bow = GridSearchCV(svm_clf, param_grid_svm, cv=5, scoring='accuracy')\n",
    "grid_search_rf_bow = GridSearchCV(rf_clf, param_grid_rf, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the grid search objects to the data\n",
    "grid_search_svm_bow.fit(bow_train_dict, train_set['label']) \n",
    "grid_search_rf_bow.fit(bow_train_dict, train_set['label'])  \n",
    "\n",
    "# Get the best parameters and scores\n",
    "best_params_svm_bow = grid_search_svm_bow.best_params_\n",
    "best_score_svm_bow = grid_search_svm_bow.best_score_\n",
    "best_params_rf_bow = grid_search_rf_bow.best_params_\n",
    "best_score_rf_bow = grid_search_rf_bow.best_score_\n",
    "\n",
    "# Print the results\n",
    "print(f'SVM with BoW best params: {best_params_svm_bow}')\n",
    "print(f'SVM with BoW best score: {best_score_svm_bow}')\n",
    "print(f'RF with BoW best params: {best_params_rf_bow}')\n",
    "print(f'RF with BoW best score: {best_score_rf_bow}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/basitnadeem/opt/miniconda3/envs/minimal_ds/lib/python3.10/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- labels\n",
      "- sentence_id\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- 000\n",
      "- 10\n",
      "- 100\n",
      "- 11\n",
      "- 12\n",
      "- ...\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 73 features, but SVC is expecting 501 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/zz/g5kmpjm90hx6rdzn5t_d4n4r0000gn/T/ipykernel_56467/2921065400.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Predict on the test set using the best models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msvm_tfidf_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGS_svm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_idf_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#rf_tfidf_pred = GS_rf.best_estimator_.predict(tf_idf_test.iloc[:, 1:-1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#svm_bow_pred = grid_search_svm_bow.best_estimator_.predict(bow_test.iloc[:, 1:-1])  # Replace 'bow_test' with your BoW test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/minimal_ds/lib/python3.10/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    789\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    792\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/minimal_ds/lib/python3.10/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m         \"\"\"\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/minimal_ds/lib/python3.10/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_validate_for_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m             X = self._validate_data(\n\u001b[0m\u001b[1;32m    593\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m                 \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/minimal_ds/lib/python3.10/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/minimal_ds/lib/python3.10/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    401\u001b[0m                 \u001b[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m                 \u001b[0;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: X has 73 features, but SVC is expecting 501 features as input."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Predict on the test set using the best models\n",
    "svm_tfidf_pred = GS_svm.best_estimator_.predict(tf_idf_test.iloc[:, 1:-1])\n",
    "rf_tfidf_pred = GS_rf.best_estimator_.predict(tf_idf_test.iloc[:, 1:-1])\n",
    "#svm_bow_pred = grid_search_svm_bow.best_estimator_.predict(bow_test.iloc[:, 1:-1])  \n",
    "#rf_bow_pred = grid_search_rf_bow.best_estimator_.predict(bow_test.iloc[:, 1:-1])  \n",
    "\n",
    "# Calculate the accuracies for the test set\n",
    "svm_tfidf_acc_test = accuracy_score(test_set['label'], svm_tfidf_pred)\n",
    "rf_tfidf_acc_test = accuracy_score(test_set['label'], rf_tfidf_pred)\n",
    "#svm_bow_acc_test = accuracy_score(test_set['label'], svm_bow_pred)\n",
    "#rf_bow_acc_test = accuracy_score(test_set['label'], rf_bow_pred)\n",
    "\n",
    "# Create a table and a plot for the results\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a DataFrame for the results\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['SVM', 'RF', 'SVM', 'RF'],\n",
    "    'Feature': ['TF-IDF', 'TF-IDF', 'BoW', 'BoW'],\n",
    "    #'Validation Accuracy': [best_score_svm_tfidf, best_score_rf_tfidf, best_score_svm_bow, best_score_rf_bow],\n",
    "    #'Test Accuracy': [svm_tfidf_acc_test, rf_tfidf_acc_test, svm_bow_acc_test, rf_bow_acc_test]\n",
    "    'Validation Accuracy': [ best_score_svm_tf_idf, best_score_rf_tf_idf],\n",
    "    'Test Accuracy': [svm_tfidf_acc_test, rf_tfidf_acc_test] \n",
    "})\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Feature', y='Test Accuracy', hue='Model', data=results)\n",
    "plt.title('Test Accuracy of Models with Different Features')\n",
    "plt.show()\n",
    "\n",
    "# Print the table\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Identify the best performing model\n",
    "best_model = results.iloc[results['Test Accuracy'].idxmax()]\n",
    "\n",
    "# Use the best model to predict the test set labels\n",
    "if best_model['Model'] == 'SVM' and best_model['Feature'] == 'TF-IDF':\n",
    "    best_pred = svm_tfidf_pred\n",
    "elif best_model['Model'] == 'RF' and best_model['Feature'] == 'TF-IDF':\n",
    "    best_pred = rf_tfidf_pred\n",
    "elif best_model['Model'] == 'SVM' and best_model['Feature'] == 'BoW':\n",
    "    best_pred = svm_bow_pred\n",
    "elif best_model['Model'] == 'RF' and best_model['Feature'] == 'BoW':\n",
    "    best_pred = rf_bow_pred\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(test_set['label'], best_pred)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels='', yticklabels='') # unique labels \n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.title('Confusion Matrix for the Best Performing Model')\n",
    "plt.show()\n",
    "\n",
    "# Analyze the confusion matrix\n",
    "# Identify any significant confusions across classes\n",
    "# (analysis here)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Extract feature vectors for the test set\n",
    "#feature_vectors_test = model.named_steps['your_feature_extraction_step_name'].transform(test_set)\n",
    "\n",
    "# Step 2: Use t-SNE to project feature vectors to 2-dimensional space\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "X_2d = tsne.fit_transform(feature_vectors_test)\n",
    "\n",
    "# Step 3: Create two scatter plots\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 5))\n",
    "\n",
    "# Step 4: Scatter plot for true labels\n",
    "scatter = axes[0].scatter(X_2d[:, 0], X_2d[:, 1], c=test_set['label'], cmap='viridis')\n",
    "axes[0].set_title('True Labels')\n",
    "legend1 = axes[0].legend(*scatter.legend_elements(), title=\"Classes\")\n",
    "axes[0].add_artist(legend1)\n",
    "\n",
    "# Step 5: Scatter plot for predicted labels\n",
    "predicted_labels = model.predict(test_set)\n",
    "scatter = axes[1].scatter(X_2d[:, 0], X_2d[:, 1], c=predicted_labels, cmap='viridis')\n",
    "axes[1].set_title('Predicted Labels')\n",
    "legend2 = axes[1].legend(*scatter.legend_elements(), title=\"Classes\")\n",
    "axes[1].add_artist(legend2)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"section-optional\"></a><h2 style=\"color:rgb(0,120,170)\">Task C: Linear Model Interpretability (2 extra points)</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgb(224, 243, 255)\">\n",
    "Train a logistic regression model on one of the document representations. Take the coefficient weights, learned by the model, on each dimension (which here corresponds to each token in the dictionary). Separately for each class, study what are the tokens that have the highest contributions/importance for the predictions of the model.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 - Top 5 tokens:\n",
      "crop: 1.1827844966911876\n",
      "agricultural: 1.129246518132164\n",
      "sexual: 1.0419295877351107\n",
      "harvest: 1.0219479676132195\n",
      "maize: 0.9828235507242286\n",
      "\n",
      "Class 1 - Top 5 tokens:\n",
      "stressed: 1.1895164674520702\n",
      "staple: 0.7806987008529056\n",
      "market: 0.7117533583487122\n",
      "21: 0.6348010406218262\n",
      "lean: 0.6305368266508338\n",
      "\n",
      "Class 2 - Top 5 tokens:\n",
      "school: 2.6816138884653427\n",
      "education: 2.5932860331258913\n",
      "child: 1.371121051199711\n",
      "measles: 1.0732303820847888\n",
      "student: 1.0443261737147624\n",
      "\n",
      "Class 3 - Top 5 tokens:\n",
      "food: 2.34410572379981\n",
      "ipc: 1.0420345211566626\n",
      "crop: 0.9576288821483436\n",
      "insecure: 0.8868484831633425\n",
      "price: 0.8668728144502404\n",
      "\n",
      "Class 4 - Top 5 tokens:\n",
      "health: 2.0079953689030807\n",
      "malaria: 1.5748859010481475\n",
      "case: 1.401742459557337\n",
      "dengue: 1.3166119925338553\n",
      "cholera: 1.211757206741559\n",
      "\n",
      "Class 5 - Top 5 tokens:\n",
      "livestock: 1.1509233811187634\n",
      "livelihood: 1.1416828980606162\n",
      "crop: 0.9502820339719801\n",
      "income: 0.9180396659909594\n",
      "maize: 0.8193007201434109\n",
      "\n",
      "Class 6 - Top 5 tokens:\n",
      "road: 1.7114670663695764\n",
      "wfp: 1.1778767076039842\n",
      "26: 0.9987269346518327\n",
      "remained: 0.961970119520492\n",
      "additional: 0.8645702106845653\n",
      "\n",
      "Class 7 - Top 5 tokens:\n",
      "power: 1.5703000157844271\n",
      "fuel: 1.2509692720121701\n",
      "item: 1.131480259901709\n",
      "need: 0.9896394564582569\n",
      "price: 0.9250957398735218\n",
      "\n",
      "Class 8 - Top 5 tokens:\n",
      "malnutrition: 2.276241233539963\n",
      "sam: 1.6728684900875834\n",
      "child: 1.556838106068834\n",
      "severely: 1.462688932457709\n",
      "nutrition: 1.4601679387089168\n",
      "\n",
      "Class 9 - Top 5 tokens:\n",
      "protection: 1.020925234677654\n",
      "detention: 0.9084950858816894\n",
      "journalist: 0.8717481490855982\n",
      "stressed: 0.8690480063357534\n",
      "right: 0.7967500347954907\n",
      "\n",
      "Class 10 - Top 5 tokens:\n",
      "shelter: 1.4966331729247186\n",
      "house: 1.4765946075360954\n",
      "home: 0.9673500582245192\n",
      "including: 0.8662137228173498\n",
      "people: 0.7703865160348964\n",
      "\n",
      "Class 11 - Top 5 tokens:\n",
      "water: 2.368707559609593\n",
      "wash: 1.5412158597507033\n",
      "latrine: 1.4003360084839083\n",
      "infection: 0.8888113652290962\n",
      "cereal: 0.7415190774844468\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Step 1: Train logistic regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(tf_idf_train.iloc[:, 1:-1], train_set['label'])\n",
    "\n",
    "# Step 2: Extract coefficient weights\n",
    "coefficients = model.coef_\n",
    "\n",
    "# Step 3: Identify tokens with the highest contributions for each class\n",
    "feature_names = list(bow_train_dict.keys())  # Get feature names\n",
    "top_n_tokens = 5  # Number of top tokens to display\n",
    "\n",
    "for i in range(coefficients.shape[0]):\n",
    "    class_weights = coefficients[i]\n",
    "    sorted_indices = class_weights.argsort()[::-1]\n",
    "    top_tokens = [(feature_names[j], class_weights[j]) for j in sorted_indices[:top_n_tokens]]\n",
    "    \n",
    "    print(f\"Class {i} - Top {top_n_tokens} tokens:\")\n",
    "    for token, weight in top_tokens:\n",
    "        print(f\"{token}: {weight}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
